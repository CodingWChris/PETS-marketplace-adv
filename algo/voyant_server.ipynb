{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# info session \n",
    "docker voyant\n",
    "url:[https://github.com/voyanttools/docker/wiki/Voyant-Docker-Tutorial]\n",
    "\n",
    "shared server\n",
    "url:[https://github.com/voyanttools/VoyantServer/wiki/Running-as-a-Shared-Server#starting-voyantserver-from-the-command-line]\n",
    "\n",
    "voyant embed \n",
    "url:[https://voyant-tools.org/docs/tutorial-embedding.html]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "from email.parser import Parser\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_anonymizer.entities import OperatorConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enron email dataset\n",
    "file_path = '../data/inputs/enron/enron_subset.csv'\n",
    "\n",
    "# Read the file\n",
    "# if file_path.endswith('.csv'):\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     text = ' '.join(df['message'].dropna().tolist())\n",
    "# else:\n",
    "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#         text = file.read()\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>allen-p/all_documents/458.</td>\n",
       "      <td>Message-ID: &lt;20430828.1075855696096.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>allen-p/all_documents/459.</td>\n",
       "      <td>Message-ID: &lt;18425275.1075855696118.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>allen-p/all_documents/46.</td>\n",
       "      <td>Message-ID: &lt;24036204.1075855666506.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>allen-p/all_documents/460.</td>\n",
       "      <td>Message-ID: &lt;33307764.1075855696139.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>allen-p/all_documents/461.</td>\n",
       "      <td>Message-ID: &lt;15009418.1075855696162.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file  \\\n",
       "0         allen-p/_sent_mail/1.   \n",
       "1        allen-p/_sent_mail/10.   \n",
       "2       allen-p/_sent_mail/100.   \n",
       "3      allen-p/_sent_mail/1000.   \n",
       "4      allen-p/_sent_mail/1001.   \n",
       "..                          ...   \n",
       "995  allen-p/all_documents/458.   \n",
       "996  allen-p/all_documents/459.   \n",
       "997   allen-p/all_documents/46.   \n",
       "998  allen-p/all_documents/460.   \n",
       "999  allen-p/all_documents/461.   \n",
       "\n",
       "                                               message  \n",
       "0    Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "1    Message-ID: <15464986.1075855378456.JavaMail.e...  \n",
       "2    Message-ID: <24216240.1075855687451.JavaMail.e...  \n",
       "3    Message-ID: <13505866.1075863688222.JavaMail.e...  \n",
       "4    Message-ID: <30922949.1075863688243.JavaMail.e...  \n",
       "..                                                 ...  \n",
       "995  Message-ID: <20430828.1075855696096.JavaMail.e...  \n",
       "996  Message-ID: <18425275.1075855696118.JavaMail.e...  \n",
       "997  Message-ID: <24036204.1075855666506.JavaMail.e...  \n",
       "998  Message-ID: <33307764.1075855696139.JavaMail.e...  \n",
       "999  Message-ID: <15009418.1075855696162.JavaMail.e...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "    email = Parser().parsestr(text)\n",
    "    \n",
    "    return {\n",
    "        \"email_body\": email.get_payload(),\n",
    "        \"sender\": email[\"From\"],\n",
    "        \"receiver\": email[\"To\"],\n",
    "        \"date\": email[\"Date\"],\n",
    "        \"subject\": email[\"Subject\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_data = df[\"message\"].apply(extract)\n",
    "df = df.join(pd.DataFrame(email_data.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp(text):\n",
    "    \"\"\"Clean and tokenize text\"\"\"\n",
    "    # Remove HTML tags\n",
    "    clean = re.compile('<.*?>')\n",
    "    text = re.sub(clean, '', text)\n",
    "\n",
    "    # Split into words and sentences\n",
    "    sen_tokens = sent_tokenize(text)\n",
    "    wrd_tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords & punctuation\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    filtered_wrds_token = [word for word in wrd_tokens if word.isalnum() and word not in stopwords and word not in string.punctuation]\n",
    "    \n",
    "    return filtered_wrds_token, sen_tokens, ' '.join(filtered_wrds_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text):\n",
    "    \"\"\"Clean and tokenize text\"\"\"\n",
    "    # Remove HTML tags\n",
    "    clean = re.compile('<.*?>')\n",
    "    text = re.sub(clean, '', text)\n",
    "    wrd_tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords & punctuation\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    filtered_wrds_token = [word for word in wrd_tokens if word.isalnum() and word not in stopwords and word not in string.punctuation]\n",
    "    \n",
    "    return ' '.join(filtered_wrds_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse engine\n",
    "configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [{\"lang_code\": 'en', \"model_name\": \"en_core_web_sm\"}],\n",
    "}\n",
    "provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "nlp_engine = provider.create_engine()\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=['en'])\n",
    "\n",
    "# mask engine\n",
    "anonymizer = AnonymizerEngine()\n",
    "operator_config = {\n",
    "    \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"<PERSON>\"}),\n",
    "    \"LOCATION\": OperatorConfig(\"replace\", {\"new_value\": \"<LOCATION>\"}),\n",
    "    \"DATE_TIME\": OperatorConfig(\"replace\", {\"new_value\": \"<DATE_TIME>\"}),\n",
    "    \"ORGANIZATION\": OperatorConfig(\"replace\", {\"new_value\": \"<ORGANIZATION>\"}),\n",
    "    \"PHONE_NUMBER\": OperatorConfig(\"replace\", {\"new_value\": \"<PHONE_NUMBER>\"}),\n",
    "    \"EMAIL_ADDRESS\": OperatorConfig(\"replace\", {\"new_value\": \"<EMAIL_ADDRESS>\"}),\n",
    "    \"CREDIT_CARD\": OperatorConfig(\"replace\", {\"new_value\": \"<CREDIT_CARD>\"}),\n",
    "}\n",
    "\n",
    "def PII_detection_masking(text):\n",
    "    # do the analyze and masking \n",
    "    chunk_size = 10000\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    masked_text = []\n",
    "    for chunk in chunks:\n",
    "        results = analyzer.analyze(text=chunk, language='en')\n",
    "        masked_chunk = anonymizer.anonymize(text=chunk, analyzer_results=results,operators=operator_config)\n",
    "        masked_text.append(masked_chunk.text)\n",
    "\n",
    "    return ' '.join(masked_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking\n",
    "df['masked_text'] = df['email_body'].apply(PII_detection_masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleasing \n",
    "df['clean_text'] = df['masked_text'].apply(cleansing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date cleasing\n",
    "df['time'] = df['date'].str[:-12].apply(lambda x: datetime.strptime(x, '%a, %d %b %Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>email_body</th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\r\\n\\r\\n</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td></td>\n",
       "      <td>Here is our forecast\\r\\n\\r\\n</td>\n",
       "      <td>forecast</td>\n",
       "      <td>2001-05-14 16:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>traveling business meeting takes fun trip espe...</td>\n",
       "      <td>2001-05-04 13:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>leah.arsdall@enron.com</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>test successful way go</td>\n",
       "      <td>2000-10-18 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\r\\n\\r\\n Can you send me a schedule of t...</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td></td>\n",
       "      <td>&lt;PERSON&gt;,\\r\\n\\r\\n Can you send me a schedule o...</td>\n",
       "      <td>send schedule salary level everyone scheduling...</td>\n",
       "      <td>2000-10-23 06:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Let's shoot for &lt;DATE_TIME&gt; at 11:45.</td>\n",
       "      <td>let shoot</td>\n",
       "      <td>2000-08-31 05:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                          email_body                   sender  \\\n",
       "0                      Here is our forecast\\r\\n\\r\\n   phillip.allen@enron.com   \n",
       "1  Traveling to have a business meeting takes the...  phillip.allen@enron.com   \n",
       "2                     test successful.  way to go!!!  phillip.allen@enron.com   \n",
       "3  Randy,\\r\\n\\r\\n Can you send me a schedule of t...  phillip.allen@enron.com   \n",
       "4                Let's shoot for Tuesday at 11:45.    phillip.allen@enron.com   \n",
       "\n",
       "                  receiver                                   date    subject  \\\n",
       "0     tim.belden@enron.com  Mon, 14 May 2001 16:39:00 -0700 (PDT)              \n",
       "1  john.lavorato@enron.com   Fri, 4 May 2001 13:51:00 -0700 (PDT)        Re:   \n",
       "2   leah.arsdall@enron.com  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)   Re: test   \n",
       "3    randall.gay@enron.com  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)              \n",
       "4     greg.piper@enron.com  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  Re: Hello   \n",
       "\n",
       "                                         masked_text  \\\n",
       "0                      Here is our forecast\\r\\n\\r\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  <PERSON>,\\r\\n\\r\\n Can you send me a schedule o...   \n",
       "4            Let's shoot for <DATE_TIME> at 11:45.     \n",
       "\n",
       "                                          clean_text                time  \n",
       "0                                           forecast 2001-05-14 16:39:00  \n",
       "1  traveling business meeting takes fun trip espe... 2001-05-04 13:51:00  \n",
       "2                             test successful way go 2000-10-18 03:00:00  \n",
       "3  send schedule salary level everyone scheduling... 2000-10-23 06:13:00  \n",
       "4                                          let shoot 2000-08-31 05:07:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to date and counts\n",
    "date_counts = df['time'].dt.date.value_counts().sort_index()  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(date_counts.index, date_counts.values, color='b', alpha=0.6)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Email Date Distribution')\n",
    "plt.xticks(rotation=45) \n",
    "plt.savefig('/Users/itschris/Desktop/Pontus-X/repo/PETS-marketplace-adv/outputs/date_distribution')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(date_counts.values, bins=50, kde=True, color=\"purple\")\n",
    "\n",
    "plt.xlabel(\"Emails Per Day\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Emails Per Day\")\n",
    "plt.savefig('/Users/itschris/Desktop/Pontus-X/repo/PETS-marketplace-adv/outputs/email_per_day_distribution')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\anaconda3\\envs\\pontusX\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Chris\\.cache\\huggingface\\hub\\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tokenizer and classifier download for sentiment analysis \n",
    "# model capable for English, Dutch, German, French, Italian, Spanish  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "sentiment_classifier = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentiment analysis over date time aggregation  \n",
    "\n",
    "def sentiment_classication(df):\n",
    "    date = df.get('time')\n",
    "    raw_text = df.get('masked_text').tolist()\n",
    "    clean_text = [re.sub(r'[\\r\\n]+', '', raw) for raw in raw_text]\n",
    "    sentiment_df = pd.DataFrame({'date': date.tolist() , 'text' : clean_text})\n",
    "    sentiment_Scores = []\n",
    "    sentiment_labels = []\n",
    "\n",
    "    \n",
    "    for email_body in sentiment_df['text']:\n",
    "        tokens = tokenizer(email_body, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = sentiment_classifier(**tokens)\n",
    "        \n",
    "        # dim = 1 -> regulate along the row (prob for each class) \n",
    "        score = outputs.logits.softmax(dim=1)\n",
    "        # dim = 0 -> average the score for each class\n",
    "        sentiment_score = score.mean(dim=0)\n",
    "        sentiment_label = sentiment_score.argmax().item()\n",
    "        \n",
    "        sentiment_Scores.append(sentiment_score.tolist())\n",
    "        sentiment_labels.append(sentiment_label)\n",
    "\n",
    "    sentiment_df['sentiment_score'] = sentiment_Scores\n",
    "    sentiment_df['sentiment_label'] = sentiment_labels\n",
    "    \n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = sentiment_classication(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>total</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-12-31 16:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-10 07:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-11 06:39:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 11:39:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 05:35:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-14 09:39:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-14 10:24:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-14 10:32:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-14 13:39:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-14 16:39:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment_label      0  1  2  3  4  total  mean\n",
       "date                                           \n",
       "1979-12-31 16:00:00  1  0  1  1  2      5   1.0\n",
       "1999-12-10 07:00:00  0  0  0  2  0      2   0.4\n",
       "1999-12-11 06:39:00  0  2  0  0  0      2   0.4\n",
       "2000-01-04 11:39:00  0  0  0  1  0      1   0.2\n",
       "2000-01-05 05:35:00  2  0  0  0  0      2   0.4\n",
       "...                 .. .. .. .. ..    ...   ...\n",
       "2001-05-14 09:39:00  1  0  0  0  0      1   0.2\n",
       "2001-05-14 10:24:00  1  0  0  0  0      1   0.2\n",
       "2001-05-14 10:32:00  1  0  0  0  0      1   0.2\n",
       "2001-05-14 13:39:00  0  0  0  1  0      1   0.2\n",
       "2001-05-14 16:39:00  0  0  0  0  1      1   0.2\n",
       "\n",
       "[650 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate sentiment label by date\n",
    "aggregate_df = sentiment_df.groupby('date')['sentiment_label'].value_counts().unstack().fillna(0).astype(int)\n",
    "aggregate_df['total'] = aggregate_df.sum(axis=1)\n",
    "aggregate_df['mean'] = aggregate_df.drop(columns='total').mean(axis=1)\n",
    "\n",
    "\n",
    "aggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['0', '1', '2', '3', '4'], dtype='object', name='sentiment_label')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sentiment_columns = [\u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m4\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43maggregate_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentiment_columns\u001b[49m\u001b[43m]\u001b[49m.plot(kind=\u001b[33m'\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m'\u001b[39m, stacked=\u001b[38;5;28;01mTrue\u001b[39;00m, figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      4\u001b[39m plt.plot(aggregate_df.index, aggregate_df[\u001b[33m'\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m'\u001b[39m], color=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mTotal Sentiments\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m2\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mSentiment Distribution Over Time\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chris\\anaconda3\\envs\\pontusX\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chris\\anaconda3\\envs\\pontusX\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chris\\anaconda3\\envs\\pontusX\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['0', '1', '2', '3', '4'], dtype='object', name='sentiment_label')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "aggregate_df['']\n",
    "# sentiment_columns = ['0', '1', '2', '3', '4']\n",
    "# aggregate_df[sentiment_columns].plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "plt.plot(aggregate_df.index, aggregate_df['total'], color='black', marker='o', label='Total Sentiments', linewidth=2)\n",
    "plt.title('Sentiment Distribution Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment Count')\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## official hosted voyant server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_official_voyant(text, return_url=False):\n",
    "    \"\"\"Send text to Voyant Tools and return/open the URL\"\"\"\n",
    "    \n",
    "    # Use the public Voyant Tools server with the correct endpoint\n",
    "    base_url = \"https://voyant-tools.org/\"\n",
    "    \n",
    "    # Create form data\n",
    "    data = {\n",
    "        'inputFormat': 'text',\n",
    "        'input': text\n",
    "    }\n",
    "    \n",
    "    # Send POST request\n",
    "    try:\n",
    "        response = requests.post(base_url, data=data)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the corpus ID from the response URL\n",
    "            corpus_url = response.url\n",
    "            \n",
    "            if return_url:\n",
    "                return corpus_url\n",
    "            else:\n",
    "                webbrowser.open(corpus_url)\n",
    "                return \"Opened in Voyant Tools\"\n",
    "        else:\n",
    "            return f\"Error: Server returned status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_email = ' '.join(df['clean_text'])\n",
    "\n",
    "url = send_to_official_voyant(all_email,return_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://voyant-tools.org/?corpus=b38fa06c994f8a9b609f7dfa8761be63'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attampted but not working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_voyant_large_text(text, return_url=False):\n",
    "    \"\"\"Create a Voyant Tools corpus and return/open the URL\"\"\"\n",
    "    # Use the public Voyant Tools server\n",
    "    base_url = \"https://voyant-tools.org/upload\"\n",
    "    \n",
    "    # Create a temporary file with the text\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:\n",
    "        f.write(text)\n",
    "        temp_filename = f.name\n",
    "    \n",
    "    # Create multipart form data\n",
    "    files = {\n",
    "        'upload': (os.path.basename(temp_filename), open(temp_filename, 'rb'), 'text/plain')\n",
    "    }\n",
    "    \n",
    "    # Upload the file\n",
    "    response = requests.post(base_url, files=files)\n",
    "    \n",
    "    # Clean up temporary file\n",
    "    os.unlink(temp_filename)\n",
    "    \n",
    "    # Get the corpus ID from the response\n",
    "    if response.status_code == 200:\n",
    "        corpus_url = f\"https://voyant-tools.org/?corpus={response.text.strip()}\"\n",
    "        \n",
    "        if return_url:\n",
    "            return corpus_url\n",
    "        else:\n",
    "            webbrowser.open(corpus_url)\n",
    "            return \"Opened in Voyant Tools\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.reason}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stand alone voyant server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_local_voyant(text, port = 8888, return_url=False):\n",
    "    \"\"\"Send text to Voyant Tools and return/open the URL\"\"\"\n",
    "    \n",
    "    # connect to local server \n",
    "    base_url = f\"http://localhost:{port}\"\n",
    "    \n",
    "    # Create form data\n",
    "    data = {\n",
    "        'inputFormat': 'text',\n",
    "        'input': text\n",
    "    }\n",
    "    \n",
    "    # Send POST request\n",
    "    try:\n",
    "        response = requests.post(base_url, data=data)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the corpus ID from the response URL\n",
    "            corpus_url = response.url\n",
    "            \n",
    "            if return_url:\n",
    "                return corpus_url\n",
    "            else:\n",
    "                webbrowser.open(corpus_url)\n",
    "                return \"Opened in Voyant Tools\"\n",
    "        else:\n",
    "            return f\"Error: Server returned status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:8888/?corpus=2333989e10d8d6420cd3953462d33dcf'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_email = ' '.join(df['clean_text'])\n",
    "url = send_to_local_voyant(all_email,return_url=True)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'inputFormat': 'text',\n",
    "    'input': all_email\n",
    "}\n",
    "res = requests.post('http://localhost:8888',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2333989e10d8d6420cd3953462d33dcf'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.url\n",
    "\n",
    "match = re.search(r'corpus=([a-f0-9]+)', res.url)\n",
    "match.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed voyant into html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_local_voyant_html(text, output_path='../outputs/voyant_analysis.html', port=8888):\n",
    "    \"\"\"Generate a standalone HTML page with Voyant visualizations using local Voyant server\"\"\"\n",
    "\n",
    "    data = {\n",
    "        'inputFormat': 'text',\n",
    "        'input': text\n",
    "    }\n",
    "    \n",
    "    # Send to local Voyant server\n",
    "    base_url = f'http://localhost:{port}'\n",
    "    response = requests.post(base_url, data=data)\n",
    "\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to connect to Voyant: {response.status_code}\")\n",
    "\n",
    "    match = re.search(r'corpus=([a-f0-9]+)', url)\n",
    "    corpus = match.group(1)\n",
    "    \n",
    "    cirrus_url = f'http://localhost:8888/tool/Cirrus/?corpus={corpus}'\n",
    "    summary_url = f'http://localhost:8888/tool/Summary/?corpus={corpus}'\n",
    "    CorpusCollocates_url = f'http://localhost:8888/tool/CorpusCollocates/?corpus={corpus}'\n",
    "\n",
    "\n",
    "\n",
    "    # Generate HTML with embedded iframes\n",
    "    html_content = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Text Analysis with Voyant</title>\n",
    "            <meta charset=\"utf-8\">\n",
    "            <style>\n",
    "                body {{\n",
    "                    margin: 0;\n",
    "                    padding: 0;\n",
    "                    background-color: #f5f5f5;\n",
    "                }}\n",
    "                .container {{ \n",
    "                    max-width: 1400px; \n",
    "                    margin: 0 auto; \n",
    "                    padding: 40px 20px;\n",
    "                }}\n",
    "                .header {{\n",
    "                    text-align: center;\n",
    "                    margin-bottom: 40px;\n",
    "                    color: #2c3e50;\n",
    "                }}\n",
    "                .header h1 {{\n",
    "                    font-size: 2.5em;\n",
    "                    margin-bottom: 10px;\n",
    "                }}\n",
    "                .header p {{\n",
    "                    color: #7f8c8d;\n",
    "                    font-size: 1.1em;\n",
    "                }}\n",
    "                .grid-container {{\n",
    "                    display: grid;\n",
    "                    grid-template-columns: repeat(2, 1fr);\n",
    "                    gap: 30px;\n",
    "                    margin-top: 20px;\n",
    "                }}\n",
    "                .tool-container {{\n",
    "                    background: white;\n",
    "                    border-radius: 10px;\n",
    "                    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "                    padding: 20px;\n",
    "                    transition: transform 0.2s;\n",
    "                }}\n",
    "                .tool-container:hover {{\n",
    "                    transform: translateY(-5px);\n",
    "                }}\n",
    "                .tool-container h2 {{\n",
    "                    color: #2c3e50;\n",
    "                    margin: 0 0 15px 0;\n",
    "                    padding-bottom: 10px;\n",
    "                    border-bottom: 2px solid #e0e0e0;\n",
    "                    font-size: 1.5em;\n",
    "                }}\n",
    "                iframe {{\n",
    "                    width: 100%;\n",
    "                    height: 500px;\n",
    "                    border: none;\n",
    "                    border-radius: 5px;\n",
    "                }}\n",
    "                .full-width {{\n",
    "                    grid-column: 1 / -1;\n",
    "                }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"container\">\n",
    "                <div class=\"header\">\n",
    "                    <h1>Text Analysis Visualization</h1>\n",
    "                    <p>Interactive analysis powered by Voyant Tools</p>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"grid-container\">\n",
    "                    <div class=\"tool-container\">\n",
    "                        <h2>📊 Word Cloud</h2>\n",
    "                        <iframe src={cirrus_url}></iframe>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"tool-container\">\n",
    "                        <h2>📈 Word Trends</h2>\n",
    "                        <iframe src='{response.url}&view=Trends'></iframe>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"tool-container full-width\">\n",
    "                        <h2>📝 Document Summary</h2>\n",
    "                        <iframe src='{summary_url}'></iframe>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"tool-container full-width\">\n",
    "                        <h2>🔗 Word Connections</h2>\n",
    "                        <iframe src='{CorpusCollocates_url}'></iframe>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    abs_path = os.path.abspath(output_path)\n",
    "    \n",
    "    # Convert to file URL format\n",
    "    if os.name == 'nt':  # for Windows\n",
    "        file_url = f'file:///{abs_path.replace(os.sep, \"/\")}'\n",
    "    else:  # for unix-like systems\n",
    "        file_url = f'file://{abs_path}'\n",
    "    \n",
    "    return file_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_email = ' '.join(df['clean_text'])\n",
    "result = generate_local_voyant_html(all_email)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "Since we are using the local host server, to let the end user have the access to the generated HTML, we have to change the localhost to a shared/dockered server. And provide the endpoint for the end user to access our server!!! \n",
    "\n",
    "**more research on this parted needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \n",
    "def func():\n",
    "    #noth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pontusX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
